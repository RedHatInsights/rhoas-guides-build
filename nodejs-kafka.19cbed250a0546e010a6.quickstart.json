{"apiVersion":"console.openshift.io/v1","kind":"QuickStarts","metadata":{"name":"nodejs","annotations":{"draft":false,"order":5},"labels":{"service-category/application-services":"true","product/rhosak":"true","technology":"node.js"}},"spec":{"version":0.1,"type":{"text":"Quick start","color":"green"},"displayName":"Using Node.js applications with Kafka instances in Red Hat OpenShift Streams for Apache Kafka","durationMinutes":10,"icon":"data:image/svg+xml;base64,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","description":"<div id=\"description\" class=\"exampleblock\">\n<div class=\"content\">\n<div class=\"paragraph\">\n<p>Manually connect a Node.js application to a Kafka instance and then produce and consume messages.</p>\n</div>\n</div>\n</div>","prerequisites":["A running Kafka instance (see <a href=\"https://console.redhat.com/application-services/learning-resources?quickstart=getting-started\">Getting started with OpenShift Streams for Apache Kafka</a>)","A command-line terminal application","Git","An IDE","Node.js 14 or later"],"introduction":"<div id=\"introduction\" class=\"exampleblock\">\n<div class=\"content\">\n<div class=\"paragraph\">\n<p>Welcome to the quick start for Red Hat OpenShift Streams for Apache Kafka with Node.js. In this quick start, you&#8217;ll use the web console to collect connection information for a Kafka instance in OpenShift Streams for Apache Kafka. Then you&#8217;ll manually configure a connection from an example <a href=\"https://nodejs.org/en/about/\" target=\"_blank\" rel=\"noopener\">Node.js</a> application to the Kafka instance and start producing and consuming messages.</p>\n</div>\n</div>\n</div>","tasks":["<div class=\"sect1\">\n<h2 id=\"proc-importing-nodejs-sample-code_using-nodejs\">Importing the Node.js sample code</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph _abstract\">\n<p>For this quick start, you&#8217;ll use sample code from the Nodeshift Application Starters <a href=\"https://github.com/nodeshift-starters/reactive-example\" target=\"_blank\" rel=\"noopener\">reactive-example</a> repository in GitHub. After you understand the concepts and tasks in this quick start, you can use your own Node.js applications with Red Hat OpenShift Streams for Apache Kafka in the same way.</p>\n</div>\n<div class=\"olist\"><div class=\"title\">Procedure</div><div class=\"task-pflist\"><h6 data-ouia-component-type=\"PF4/Title\" data-ouia-safe=\"true\" data-ouia-component-id=\"OUIA-Generated-Title-46\" class=\"pf-c-title pf-m-md task-pflist-title\">Procedure</h6><ol type=\"1\" class=\"pf-c-list task-pflist-list task-pflist-list--proc\"><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\">On the command line, clone the Nodeshift Application Starters <a href=\"https://github.com/nodeshift-starters/reactive-example\" target=\"_blank\" rel=\"noopener\">reactive-example</a> repository from GitHub.<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code>$ git clone https://github.com/nodeshift-starters/reactive-example.git</code></pre>\n</div>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\">In your IDE, open the <code>reactive-example</code> directory of the repository that you cloned.</span></li></ol></div></div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>Is the Node.js example application accessible in your IDE?</p>\n</li>\n</ul>\n</div>\n</div>\n</div>","<div class=\"sect1\">\n<h2 id=\"proc-configuring-nodejs_using-nodejs\">Configuring the Node.js example application to connect to a Kafka instance</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph _abstract\">\n<p>To enable your Node.js application to access a Kafka instance, you must configure a connection by specifying the following details:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>The bootstrap server endpoint for your Kafka instance</p>\n</li>\n<li>\n<p>The generated credentials for your Red Hat OpenShift Streams for Apache Kafka service account</p>\n</li>\n<li>\n<p>The Simple Authentication and Security Layer (SASL) mechanism that the client will use to authenticate with the Kafka instance</p>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p>In this task, you&#8217;ll create a new configuration file called <code>rhoas.env</code>. In the file, you&#8217;ll set the required bootstrap server and client credentials as environment variables.</p>\n</div>\n<div class=\"olist\"><div class=\"title\">Procedure</div><div class=\"task-pflist\"><h6 data-ouia-component-type=\"PF4/Title\" data-ouia-safe=\"true\" data-ouia-component-id=\"OUIA-Generated-Title-47\" class=\"pf-c-title pf-m-md task-pflist-title\">Procedure</h6><ol type=\"1\" class=\"pf-c-list task-pflist-list task-pflist-list--proc\"><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\">In your IDE, create a new file. Save the file with the name <code>rhoas.env</code>, at the root level of the <code>reactive-example</code> directory for the cloned repository.</span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\">In the <code>rhoas.env</code> file, set the SASL authentication mechanism and the Kafka instance client credentials as shown in the following configuration. Replace the client ID and client secret values with your own credential information. The configuration uses SASL/OAUTHBEARER authentication, which is the recommended authentication mechanism to use in OpenShift Streams for Apache Kafka.<div class=\"listingblock\">\n<div class=\"title\">Setting environment variables in the rhoas.env file</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code>KAFKA_HOST=<em>&lt;bootstrap_server&gt;</em>\nRHOAS_SERVICE_ACCOUNT_CLIENT_ID=<em>&lt;client_id&gt;</em>\nRHOAS_SERVICE_ACCOUNT_CLIENT_SECRET=<em>&lt;client_secret&gt;</em>\nKAFKA_SASL_MECHANISM=oauthbearer\nRHOAS_TOKEN_ENDPOINT_URL=https://sso.redhat.com/auth/realms/redhat-external/protocol/openid-connect/token</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The values are described as follows:</p>\n</div>\n<div class=\"openblock\">\n<div class=\"content\">\n<div class=\"ulist\">\n<ul>\n<li>\n<p><strong>bootstrap_server</strong>: The bootstrap server endpoint for your Kafka instance. To access this information for a Kafka instance in OpenShift Streams for Apache Kafka, select the options menu (three vertical dots). Click <strong>Connection</strong>.</p>\n</li>\n<li>\n<p><strong>client_id</strong>: A client credential generated when you create a service account in OpenShift Streams for Apache Kafka. You&#8217;re prompted to copy and store this credential when you create the service account.</p>\n</li>\n<li>\n<p><strong>client_secret</strong>: A client credential generated when you create a service account in OpenShift Streams for Apache Kafka. You&#8217;re prompted to copy and store this credential when you create the service account.</p>\n</li>\n</ul>\n</div>\n</div>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\">Save the <code>rhoas.env</code> file.</span></li></ol></div></div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>Did you set environment variables for the Kafka instance?</p>\n</li>\n</ul>\n</div>\n</div>\n</div>","<div class=\"sect1\">\n<h2 id=\"proc-creating-countries-topic_using-nodejs\">Creating a Kafka topic in OpenShift Streams for Apache Kafka</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph _abstract\">\n<p>The Node.js application in this quick start uses a Kafka topic called <code>countries</code> to produce and consume messages. In this task, you&#8217;ll create the <code>countries</code> topic in your Kafka instance.</p>\n</div>\n<div class=\"ulist\"><div class=\"title\">Prerequisites</div><div class=\"task-pflist\"><h6 data-ouia-component-type=\"PF4/Title\" data-ouia-safe=\"true\" data-ouia-component-id=\"OUIA-Generated-Title-48\" class=\"pf-c-title pf-m-md task-pflist-title\">Prerequisites</h6><p class=\"task-pflist-subtitle\">In addition to the prerequisites for this quick start, you have completed the following requirements for this step:</p><ul class=\"pf-c-list task-pflist-list task-pflist-list--prereq\"><li class=\"task-pflist-list__item--prereq task-pflist-list__item\"><span class=\"task-pflist-list__item__content\">You have a running Kafka instance in Red Hat OpenShift Streams for Apache Kafka.</span></li></ul></div></div>\n<div class=\"olist\"><div class=\"title\">Procedure</div><div class=\"task-pflist\"><h6 data-ouia-component-type=\"PF4/Title\" data-ouia-safe=\"true\" data-ouia-component-id=\"OUIA-Generated-Title-49\" class=\"pf-c-title pf-m-md task-pflist-title\">Procedure</h6><ol type=\"1\" class=\"pf-c-list task-pflist-list task-pflist-list--proc\"><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\">In the OpenShift Streams for Apache Kafka <a href=\"https://console.redhat.com/application-services/streams/\" target=\"_blank\" rel=\"noopener\">web console</a>, select <strong>Kafka Instances</strong> and then click the name of the Kafka instance that you want to add a topic to.</span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\">Select the <strong>Topics</strong> tab.</span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\">Click <strong>Create topic</strong> and follow the guided steps to define the topic details.<div class=\"openblock\">\n<div class=\"content\">\n<div class=\"paragraph\">\n<p>You must specify the following topic properties:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><strong>Topic name</strong>: For this quick start, enter <code>countries</code> as the topic name.</p>\n</li>\n<li>\n<p><strong>Partitions</strong>: Set the number of partitions for the topic. For this quick start, set the value to <code>1</code>.</p>\n</li>\n<li>\n<p><strong>Message retention</strong>: Set the message retention time and size. For this quick start, set the retention time to <code>A week</code> and the retention size to <code>Unlimited</code>.</p>\n</li>\n<li>\n<p><strong>Replicas</strong>: For this release of OpenShift Streams for Apache Kafka, the replica values are preconfigured. The number of partition replicas for the topic is set to <code>3</code> and the minimum number of follower replicas that must be in sync with a partition leader is set to <code>2</code>. For a trial Kafka instance, the number of replicas and the minimum in-sync replica factor are both set to <code>1</code>.</p>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p>After you complete the setup, the new topic appears on the <strong>Topics</strong> page. You can now run the Node.js application to start producing and consuming messages.</p>\n</div>\n</div>\n</div></span></li></ol></div></div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>Is the <code>countries</code> topic listed on the <strong>Topics</strong> page?</p>\n</li>\n</ul>\n</div>\n</div>\n</div>","<div class=\"sect1\">\n<h2 id=\"proc-running-nodejs-example-application_using-nodejs\">Running the Node.js example application</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph _abstract\">\n<p>After you configure your Node.js application to connect to a Kafka instance, and you create the required Kafka topic, you&#8217;re ready to run the application.</p>\n</div>\n<div class=\"paragraph\">\n<p>In this task, you&#8217;ll run the following components of the Node.js application:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>A <code>producer-backend</code> component that generates random country names and sends these names to the Kafka topic</p>\n</li>\n<li>\n<p>A <code>consumer-backend</code> component that consumes the country names from the Kafka topic</p>\n</li>\n</ul>\n</div>\n<div class=\"ulist\"><div class=\"title\">Prerequisites</div><div class=\"task-pflist\"><h6 data-ouia-component-type=\"PF4/Title\" data-ouia-safe=\"true\" data-ouia-component-id=\"OUIA-Generated-Title-50\" class=\"pf-c-title pf-m-md task-pflist-title\">Prerequisites</h6><p class=\"task-pflist-subtitle\">In addition to the prerequisites for this quick start, you have completed the following requirements for this step:</p><ul class=\"pf-c-list task-pflist-list task-pflist-list--prereq\"><li class=\"task-pflist-list__item--prereq task-pflist-list__item\"><span class=\"task-pflist-list__item__content\">You&#8217;ve configured the Node.js example application to connect to a Kafka instance.</span></li><li class=\"task-pflist-list__item--prereq task-pflist-list__item\"><span class=\"task-pflist-list__item__content\">You&#8217;ve created the <code>countries</code> topic.</span></li><li class=\"task-pflist-list__item--prereq task-pflist-list__item\"><span class=\"task-pflist-list__item__content\">You&#8217;ve set permissions for your service account to produce and consume messages in the <code>countries</code> topic. For the Node.js application in this example, the consumer group you must specify in your permissions is called <code>consumer-test</code>. To learn how to configure access permissions for a Kafka instance, see <a href=\"https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/2f4bf7cf-5de2-4254-8274-6bf71673f407\" target=\"_blank\" rel=\"noopener\">Managing account access in Red Hat OpenShift Streams for Apache Kafka</a>.</span></li></ul></div></div>\n<div class=\"olist\"><div class=\"title\">Procedure</div><div class=\"task-pflist\"><h6 data-ouia-component-type=\"PF4/Title\" data-ouia-safe=\"true\" data-ouia-component-id=\"OUIA-Generated-Title-51\" class=\"pf-c-title pf-m-md task-pflist-title\">Procedure</h6><ol type=\"1\" class=\"pf-c-list task-pflist-list task-pflist-list--proc\"><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\">On the command line, navigate to the <code>reactive-example</code> directory of the repository that you cloned.<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code>$ cd reactive-example</code></pre>\n</div>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\">Navigate to the directory for the consumer component. Use Node Package Manager (npm) to install the dependencies for this component.<div class=\"listingblock\">\n<div class=\"title\">Installing dependencies for the consumer component</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code>$ cd consumer-backend\n$ npm install</code></pre>\n</div>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\">Run the consumer component.<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code>$ node consumer.js</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>You see the Node.js application run and connect to the Kafka instance. However, because you haven&#8217;t yet run the producer component, the consumer has no country names to display.</p>\n</div>\n<div class=\"paragraph\">\n<p>If the application fails to run, review the error log in the command-line window and address any problems. Also, review the steps in this quick start to ensure that the application and Kafka topic are configured correctly.</p>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\">Open a second command-line window or tab.</span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\">On the second command line, navigate to the <code>reactive-example</code> directory of the repository that you cloned.<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code>$ cd reactive-example</code></pre>\n</div>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\">Navigate to the directory for the producer component. Use Node Package Manager to install the dependencies for this component.<div class=\"listingblock\">\n<div class=\"title\">Installing dependencies for the producer component</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code>$ cd producer-backend\n$ npm install</code></pre>\n</div>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\">Run the producer component.<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code>$ node producer.js</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>When the producer component runs, you see output like that shown in the following example:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"title\">Example output from the producer component</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code>Ghana\nRéunion\nGuatemala\nLuxembourg\nMayotte\nSyria\nUnited Kingdom\nBolivia\nHaiti</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>As shown in the example, the producer component runs and generates messages that represent country names.</p>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\">Switch back to the first command-line window.<div class=\"paragraph\">\n<p>You now see that the consumer component displays the same country names generated by the producer, and in the same order, as shown in the following example:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"title\">Example output from the consumer component</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code>Ghana\nRéunion\nGuatemala\nLuxembourg\nMayotte\nSyria\nUnited Kingdom\nBolivia\nHaiti</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The output from both components confirms that they successfully connected to the Kafka instance. The components are using the Kafka topic that you created to produce and consume messages.</p>\n</div>\n<div class=\"pf-c-alert pf-m-inline pf-m-info description-important\" aria-label=\"Info Alert\" data-ouia-component-type=\"PF4/Alert\" data-ouia-safe=\"true\" data-ouia-component-id=\"OUIA-Generated-Alert-info-28\" data-reactroot=\"\"><div class=\"pf-c-alert__icon\"><svg style=\"vertical-align:-0.125em\" fill=\"currentColor\" height=\"1em\" width=\"1em\" viewBox=\"0 0 512 512\" aria-hidden=\"true\" role=\"img\"><path d=\"M256 8C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm0 110c23.196 0 42 18.804 42 42s-18.804 42-42 42-42-18.804-42-42 18.804-42 42-42zm56 254c0 6.627-5.373 12-12 12h-88c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h12v-64h-12c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h64c6.627 0 12 5.373 12 12v100h12c6.627 0 12 5.373 12 12v24z\"></path></svg></div><h4 class=\"pf-c-alert__title\"><span class=\"pf-u-screen-reader\">Info alert:</span>NOTE</h4><div class=\"pf-c-alert__description\">You can also use the Red Hat OpenShift Streams for Apache Kafka web console to browse messages in the Kafka topic. For more information, see &lt;a href=&quot;https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/c3249a7c-b8c0-4df4-9cec-93f11877b054&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Browsing messages in the Red Hat OpenShift Streams for Apache Kafka web console&lt;/a&gt;.</div></div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\">In your IDE, in the <code>producer-backend</code> directory of the repository that you cloned, open the <code>producer.js</code> file.<div class=\"paragraph\">\n<p>Observe that the producer component is configured to process environment variables from the <code>rhoas.env</code> file that you created. The component used the bootstrap server endpoint and client credentials stored in this file to connect to the Kafka instance.</p>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\">In the <code>consumer-backend</code> directory, open the <code>consumer.js</code> file.<div class=\"paragraph\">\n<p>Observe that the consumer component is also configured to process environment variables from the <code>rhoas.env</code> file that you created.</p>\n</div></span></li></ol></div></div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>Did the producer component run and start generating random country names?</p>\n</li>\n<li>\n<p>Did the consumer component run and display the same country names generated by the producer, and in the same order?</p>\n</li>\n</ul>\n</div>\n<div id=\"conclusion\" class=\"exampleblock\">\n<div class=\"content\">\n<div class=\"paragraph\">\n<p>Congratulations! You successfully completed the OpenShift Streams for Apache Kafka Node.js quick start. You&#8217;re now ready to use your own Node.js applications with OpenShift Streams for Apache Kafka.</p>\n</div>\n</div>\n</div>\n</div>\n</div>"],"conclusion":"<div id=\"conclusion\" class=\"exampleblock\">\n<div class=\"content\">\n<div class=\"paragraph\">\n<p>Congratulations! You successfully completed the OpenShift Streams for Apache Kafka Node.js quick start. You&#8217;re now ready to use your own Node.js applications with OpenShift Streams for Apache Kafka.</p>\n</div>\n</div>\n</div>","nextQuickStart":["quarkus"]}}