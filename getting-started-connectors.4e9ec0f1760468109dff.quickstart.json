{"apiVersion":"console.openshift.io/v1","kind":"QuickStarts","metadata":{"name":"connectors-getting-started","annotations":{"draft":false,"order":6}},"spec":{"version":0.1,"type":{"text":"Quick Start","color":"green"},"displayName":"Getting started with Red Hat OpenShift Connectors","durationMinutes":20,"icon":"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzOCIgaGVpZ2h0PSIzOCIgdmlld0JveD0iMCAwIDM4IDM4Ij48ZGVmcz48c3R5bGU+LmF7ZmlsbDojZmZmO30uYntmaWxsOiNlMDA7fTwvc3R5bGU+PC9kZWZzPjxwYXRoIGQ9Ik0yOCwxSDEwYTksOSwwLDAsMC05LDlWMjhhOSw5LDAsMCwwLDksOUgyOGE5LDksMCwwLDAsOS05VjEwYTksOSwwLDAsMC05LTlaIi8+PHBhdGggY2xhc3M9ImEiIGQ9Ik0yMiwyNS42MjVIMTNhLjYyNS42MjUsMCwwLDEsMC0xLjI1aDlhMi4zNzUsMi4zNzUsMCwwLDAsMC00Ljc1SDE1YTMuNjI1LDMuNjI1LDAsMCwxLDAtNy4yNUgyNWEuNjI1LjYyNSwwLDAsMSwwLDEuMjVIMTVhMi4zNzUsMi4zNzUsMCwwLDAsMCw0Ljc1aDdhMy42MjUsMy42MjUsMCwwLDEsMCw3LjI1WiIvPjxwYXRoIGNsYXNzPSJiIiBkPSJNMjUsMTYuNjI1QTMuNjI1LDMuNjI1LDAsMSwxLDI4LjYyNSwxMywzLjYyODg2LDMuNjI4ODYsMCwwLDEsMjUsMTYuNjI1Wm0wLTZBMi4zNzUsMi4zNzUsMCwxLDAsMjcuMzc1LDEzLDIuMzc3NywyLjM3NzcsMCwwLDAsMjUsMTAuNjI1WiIvPjxwYXRoIGNsYXNzPSJiIiBkPSJNMTMsMjguNjI1QTMuNjI1LDMuNjI1LDAsMSwxLDE2LjYyNSwyNSwzLjYyODg2LDMuNjI4ODYsMCwwLDEsMTMsMjguNjI1Wm0wLTZBMi4zNzUsMi4zNzUsMCwxLDAsMTUuMzc1LDI1LDIuMzc3NywyLjM3NzcsMCwwLDAsMTMsMjIuNjI1WiIvPjwvc3ZnPg==","description":"<div id=\"description\" class=\"exampleblock\">\n<div class=\"content\">\n<div class=\"paragraph\">\n<p>Learn how to create and set up connectors in Red Hat OpenShift Connectors.</p>\n</div>\n</div>\n</div>","prerequisites":["A Red Hat identity","You've created a Kafka instance and the instance is in `Ready` state. See the _Getting started with OpenShift Streams for Apache Kafka_ quick start.","For the data sink example, open the free <a href=\"https://webhook.site\">Webhook.site</a> in a browser window. The Webhook.site page provides a unique URL that you copy. You use this URL as an HTTP data sink."],"introduction":"<div id=\"introduction\" class=\"exampleblock\">\n<div class=\"content\">\n<div class=\"paragraph\">\n<p>Welcome to the quick start for Red Hat OpenShift Connectors.</p>\n</div>\n<div class=\"paragraph\">\n<p>In this quick start, you learn how to create a source connector and sink connector and send data to and from OpenShift Streams for Apache Kafka.</p>\n</div>\n<div class=\"paragraph\">\n<p>A <strong>source</strong> connector allows you to send data from an external system to OpenShift Streams for Apache Kafka. A <strong>sink</strong> connector allows you to send data from OpenShift Streams for Apache Kafka to an external system.</p>\n</div>\n</div>\n</div>","tasks":["<div class=\"sect1\">\n<h2 id=\"proc-configuring-kafka-for-connectors_getting-started-connectors\">Configuring the OpenShift Streams for Apache Kafka instance for use with Red Hat OpenShift Connectors</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph _abstract\">\n<p>Configure your OpenShift Streams for Apache Kafka instance for use with Red Hat OpenShift Connectors by:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Creating <strong>Kafka topics</strong> to store messages sent by producers (data sources) and make them available to consumers (data sinks).</p>\n</li>\n<li>\n<p>Creating <strong>service accounts</strong> that allow you to connect and authenticate your Connectors with Kafka instances.</p>\n</li>\n<li>\n<p>Setting up <strong>access rules</strong> for the service accounts that define how your Connectors can access and use the associated Kafka instance topics.</p>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p>The number of Kafka topics and service accounts that you create, and the access rules for the service accounts, depend on your application.</p>\n</div>\n<div class=\"paragraph\">\n<p>For this example, you create one Kafka topic, named <strong>test</strong>, one service account, and you define access for the service account.</p>\n</div>\n<div class=\"olist\"><div class=\"title\">Procedure</div><div class=\"task-pflist\"><h6 data-ouia-component-type=\"PF4/Title\" data-ouia-safe=\"true\" data-ouia-component-id=\"OUIA-Generated-Title-1\" class=\"pf-c-title pf-m-md task-pflist-title\">Procedure</h6><ol type=\"1\" class=\"pf-c-list task-pflist-list task-pflist-list--proc\"><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Create a Kafka topic for your connectors:</p> <div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the OpenShift Application Services web console, select <strong>Streams for Apache Kafka</strong> &gt; <strong>Kafka Instances</strong>.</p>\n</li>\n<li>\n<p>Click the name of the Kafka instance that you want to add a topic to.</p>\n</li>\n<li>\n<p>Select the <strong>Topics</strong> tab, and then click <strong>Create topic</strong>.</p>\n</li>\n<li>\n<p>Type a unique name for your topic. For example, type <strong>test-topic</strong> for the <strong>Topic Name</strong>.</p>\n</li>\n<li>\n<p>Accept the default settings for partitions, message retention, and replicas.</p>\n</li>\n</ol>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Create a service account for connectors:</p> <div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the web console, select <strong>Service Accounts</strong>, and then click <strong>Create service account</strong>.</p>\n</li>\n<li>\n<p>Type a unique service account name (for example, <strong>test-service-acct</strong> ) and then click <strong>Create</strong>.</p>\n</li>\n<li>\n<p>Copy the generated <strong>Client ID</strong> and <strong>Client Secret</strong> to a secure location. You&#8217;ll use these credentials to configure connections to this service account.</p>\n</li>\n<li>\n<p>Select the <strong>I have copied the client ID and secret</strong> option, and then click <strong>Close</strong>.</p>\n</li>\n</ol>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Set the level of access for your new service account in the Access Control List (ACL) of the Kafka instance:</p> <div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Select <strong>Streams for Apache Kafka</strong> &gt; <strong>Kafka Instances</strong>.</p>\n</li>\n<li>\n<p>Click the name of the Kafka instance that you want the service account to access.</p>\n</li>\n<li>\n<p>Click the <strong>Access</strong> tab to view the current ACL for the Kafka instance and then click <strong>Manage access</strong>.</p>\n</li>\n<li>\n<p>From the <strong>Account</strong> drop-down menu, select the service account that you created in Step 2, and then click <strong>Next</strong>.</p>\n</li>\n<li>\n<p>Under <strong>Assign Permissions</strong>, click <strong>Add permission</strong>.</p>\n</li>\n<li>\n<p>From the drop-down menu, select <strong>Consume from a topic</strong>. Set all resource identifiers to <code>is</code> and all identifier values to <code>\"*\"</code>.</p>\n</li>\n<li>\n<p>From the <strong>Add permission</strong> drop-down menu, select <strong>Produce to a topic</strong>. Set all resource identifiers to <code>is</code> and all identifier values to <code>\"*\"</code>.</p>\n<div class=\"paragraph\">\n<p>The <code>is \"*\"</code> settings enable connectors that are configured with the service account credentials to produce and consume messages in any topic in the Kafka instance.</p>\n</div>\n</li>\n</ol>\n</div></span></li></ol></div></div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>Did you create a topic for connectors?</p>\n</li>\n<li>\n<p>Did you create a service account and save the credentials to a secure location?</p>\n</li>\n<li>\n<p>Did you set the <strong>Consume from a topic</strong> and <strong>Produce to a topic</strong> permissions for the service account?</p>\n</li>\n</ul>\n</div>\n</div>\n</div>","<div class=\"sect1\">\n<h2 id=\"proc-creating-source-connector_getting-started-connectors\">Creating a Connectors instance for a data source</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph _abstract\">\n<p>A <strong>source</strong> connector consumes events from an external data source and produces Kafka messages.</p>\n</div>\n<div class=\"paragraph\">\n<p>For this example, you create an instance of the <strong>Data Generator</strong> source connector.</p>\n</div>\n<div class=\"paragraph\">\n<p>You configure your connector to listen for events from the data source and produce a Kafka message for each event.</p>\n</div>\n<div class=\"paragraph\">\n<p>The connector sends the messages at regular intervals to the Kafka topic that you created for Connectors.</p>\n</div>\n<div class=\"olist\"><div class=\"title\">Procedure</div><div class=\"task-pflist\"><h6 data-ouia-component-type=\"PF4/Title\" data-ouia-safe=\"true\" data-ouia-component-id=\"OUIA-Generated-Title-2\" class=\"pf-c-title pf-m-md task-pflist-title\">Procedure</h6><ol type=\"1\" class=\"pf-c-list task-pflist-list task-pflist-list--proc\"><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>In the OpenShift Application Services web console, select <strong>Connectors</strong> and then click <strong>Create Connectors instance</strong>.</p> </span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Select the connector that you want to use for a data source.</p> <div class=\"paragraph\">\n<p>You can browse through the catalog of available connectors. You can also search for a particular connector by name, and filter for sink or source connectors.</p>\n</div>\n<div class=\"paragraph\">\n<p>For example, to find the <strong>Data Generator</strong> source connector, type <strong>data</strong> in the search box. The list filters to show only the <strong>Data Generator Connector</strong> card.</p>\n</div>\n<div class=\"paragraph\">\n<p>Click the card to select the connector, and then click <strong>Next</strong>.</p>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>For the <strong>Kafka instance</strong>, click the card for the OpenShift Streams for Apache Kafka instance that you configured for Connectors, and then click <strong>Next</strong>.</p> <div data-reactroot=\"\"><div class=\"pf-c-alert pf-m-inline pf-m-info description-important\" aria-label=\"Info Alert\" data-ouia-component-type=\"PF4/Alert\" data-ouia-safe=\"true\" data-ouia-component-id=\"OUIA-Generated-Alert-info-2\"><div class=\"pf-c-alert__icon\"><svg style=\"vertical-align:-0.125em\" fill=\"currentColor\" height=\"1em\" width=\"1em\" viewBox=\"0 0 512 512\" aria-hidden=\"true\" role=\"img\"><path d=\"M256 8C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm0 110c23.196 0 42 18.804 42 42s-18.804 42-42 42-42-18.804-42-42 18.804-42 42-42zm56 254c0 6.627-5.373 12-12 12h-88c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h12v-64h-12c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h64c6.627 0 12 5.373 12 12v100h12c6.627 0 12 5.373 12 12v24z\"></path></svg></div><h4 class=\"pf-c-alert__title\"><span class=\"pf-u-screen-reader\">Info alert:</span>NOTE</h4><div class=\"pf-c-alert__description\"><span>If you have not already configured a OpenShift Streams for Apache Kafka instance for Connectors, you can create a new Kafka instance by clicking <strong>Create Kafka instance</strong>. You would also need to set up and define access for a service account as described in <em>Configuring the OpenShift Streams for Apache Kafka instance for use with Red Hat OpenShift Connectors</em>.</span></div></div></div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>On the <strong>Namespace</strong> page, click <strong>Register eval namespace</strong> to provision a namespace for hosting the Connectors instances that you create.</p> </span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Click <strong>Next</strong>.</p> </span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Configure the core configuration for your connector:</p> <div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Provide a name for the connector.</p>\n</li>\n<li>\n<p>Type the <strong>Client ID</strong> and <strong>Client Secret</strong> of the service account that you created for Connectors and then click <strong>Next</strong>.</p>\n</li>\n</ol>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Provide connector-specific configuration. For the <strong>Data Generator</strong>, provide the following information:</p> <div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p><strong>Data shape Format</strong>: Accept the default, <code>application/octet-stream</code>.</p>\n</li>\n<li>\n<p><strong>Topic Names</strong>: Type the name of the topic that you created for Connectors. For example, type <strong>test-topic</strong>.</p>\n</li>\n<li>\n<p><strong>Content Type</strong>: Accept the default, <code>text/plain</code>.</p>\n</li>\n<li>\n<p><strong>Message</strong>: Type the content of the message that you want the Connector instance to send to the Kafka topic. For example, type <code>Hello World!</code>.</p>\n</li>\n<li>\n<p><strong>Period</strong>: Specify the interval (in milliseconds) at which you want the Connectors instance to send messages to the Kafka topic. For example, specify <code>10000</code>, to send a message every 10 seconds.</p>\n</li>\n</ol>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Optionally, configure the error handling policy for your Connectors instance.</p> <div class=\"paragraph\">\n<p>The options are:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><strong>stop</strong> - (the default) The Connectors instance shuts down when it encounters an error.</p>\n</li>\n<li>\n<p><strong>log</strong> - The Connectors instance sends errors to its log.</p>\n</li>\n<li>\n<p><strong>dead letter queue</strong> - The Connectors instance sends messages that it cannot handle to a dead letter topic that you define for the Connectors Kafka instance.</p>\n<div class=\"paragraph\">\n<p>For example, select <strong>log</strong>.</p>\n</div>\n</li>\n</ul>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Click <strong>Next</strong>.</p> </span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Review the summary of the configuration properties and then click <strong>Create Connectors instance</strong>.</p> <div class=\"paragraph\">\n<p>Your Connectors instance is listed in the table of Connectors. After a couple of seconds, the status of your Connectors instance changes to the <strong>Ready</strong> state and it starts producing messages and sending them to its associated Kafka topic.</p>\n</div>\n<div class=\"paragraph\">\n<p>From the connectors table, you can stop, start, and delete your Connectors instance, as well as edit its configuration, by clicking the options icon (three vertical dots).</p>\n</div></span></li></ol></div></div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>Did you create an instance of the Data Generator connector?</p>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p>In the next procedure, you can verify that the source Connectors instance is sending messages as expected by creating a sink Connectors instance that consumes the messages.</p>\n</div>\n</div>\n</div>","<div class=\"sect1\">\n<h2 id=\"proc-creating-sink-connector_getting-started-connectors\">Creating a Connectors instance for a data sink</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph _abstract\">\n<p>A <strong>sink</strong> connector consumes messages from a Kafka topic and sends them to an external system.</p>\n</div>\n<div class=\"paragraph\">\n<p>For this example, you use the <strong>HTTP Sink</strong> connector which consumes the Kafka messages (produced by the source Connectors instance) and sends the messages to an HTTP endpoint.</p>\n</div>\n<div class=\"olist\"><div class=\"title\">Procedure</div><div class=\"task-pflist\"><h6 data-ouia-component-type=\"PF4/Title\" data-ouia-safe=\"true\" data-ouia-component-id=\"OUIA-Generated-Title-3\" class=\"pf-c-title pf-m-md task-pflist-title\">Procedure</h6><ol type=\"1\" class=\"pf-c-list task-pflist-list task-pflist-list--proc\"><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>In the OpenShift Application Services web console, select <strong>Connectors</strong> and then click <strong>Create Connectors instance</strong>.</p> </span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Select the sink connector that you want to use:</p> <div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>For example, type <strong>http</strong> in the search field. The list of connectors filters to show the <strong>HTTP Sink</strong> connector.</p>\n</li>\n<li>\n<p>Click the <strong>HTTP Sink connector</strong> card and then click <strong>Next</strong>.</p>\n</li>\n</ol>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Select the OpenShift Streams for Apache Kafka instance for the connector to work with.</p> <div class=\"paragraph\">\n<p>For example, select <strong>test</strong>  and then click <strong>Next</strong>.</p>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>On the <strong>Namespace</strong> page, click the <strong>eval namespace</strong> that you created when you created the source connector.</p> </span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Click <strong>Next</strong>.</p> </span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Provide the core configuration for your connector:</p> <div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Type a unique name for the connector.</p>\n</li>\n<li>\n<p>Type the <strong>Client ID</strong> and <strong>Client Secret</strong> of the service account that you created for Connectors and then click <strong>Next</strong>.</p>\n</li>\n</ol>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Provide the connector-specific configuration for your connector. For the <strong>HTTP sink connector</strong>, provide the following information:</p> <div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p><strong>Data shape Format</strong>: Accept the default, <code>application/octet-stream</code>.</p>\n</li>\n<li>\n<p><strong>Method</strong>: Accept the default, <code>POST</code>.</p>\n</li>\n<li>\n<p><strong>URL</strong>: Type your unique URL from the <a href=\"https://webhook.site\" target=\"_blank\" rel=\"noopener\">webhook.site</a>.</p>\n</li>\n<li>\n<p><strong>Topic Names</strong>: Type the name of the topic that you used for the source Connectors instance. For example, type <strong>test-topic</strong>.</p>\n</li>\n</ol>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Optionally, configure the error handling policy for your Connectors instance. For example, select <strong>log</strong> and then click <strong>Next</strong>.</p> </span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Review the summary of the configuration properties and then click <strong>Create Connectors instance</strong>.</p> <div class=\"paragraph\">\n<p>Your Connectors instance is listed in the table of Connectors.</p>\n</div>\n<div class=\"paragraph\">\n<p>After a couple of seconds, the status of your Connectors instance changes to the <strong>Ready</strong> state. It consumes messages from the associated Kafka topic and sends them to the data sink (for this example, the data sink is the HTTP URL that you provided).</p>\n</div></span></li></ol></div></div>\n<div class=\"paragraph\">\n<div class=\"title\">Verification</div>\n<p>Open the browser tab to your custom URL for the <a href=\"https://webhook.site\" target=\"_blank\" rel=\"noopener\">webhook.site</a> to see the HTTP POST calls with the <code>\"Hello World!!\"</code> messages (that you defined in the source connector).</p>\n</div>\n<div id=\"conclusion\" class=\"exampleblock\">\n<div class=\"content\">\n<div class=\"paragraph\">\n<p>Congratulations! You successfully completed the Red Hat OpenShift Connectors Getting Started quick start.</p>\n</div>\n</div>\n</div>\n</div>\n</div>"],"conclusion":"<div id=\"conclusion\" class=\"exampleblock\">\n<div class=\"content\">\n<div class=\"paragraph\">\n<p>Congratulations! You successfully completed the Red Hat OpenShift Connectors Getting Started quick start.</p>\n</div>\n</div>\n</div>"}}