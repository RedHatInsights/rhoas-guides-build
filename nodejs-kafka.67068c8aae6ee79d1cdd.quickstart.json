{"apiVersion":"console.openshift.io/v1","kind":"QuickStarts","metadata":{"name":"nodejs","annotations":{"draft":false,"order":5}},"spec":{"version":0.1,"type":{"text":"Quick start","color":"green"},"displayName":"Using Node.js applications with Kafka instances in Red Hat OpenShift Streams for Apache Kafka","durationMinutes":10,"icon":"data:image/svg+xml;base64,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","description":"<div id=\"description\" class=\"paragraph\">\n<p>Learn how to use Node.js applications to produce and consume messages using a Kafka instance in Red Hat OpenShift Streams for Apache Kafka.</p>\n</div>","prerequisites":["A running Kafka instance (see the Getting Started quick start)","A command-line terminal application","Git","An IDE","Node.js 14.x"],"introduction":"<div id=\"introduction\" class=\"paragraph\">\n<p>Welcome to the quick start for Red Hat OpenShift Streams for Apache Kafka with Node.js. In this quick start, you&#8217;ll learn how to use the <a href=\"https://nodejs.org/en/about/\" target=\"_blank\" rel=\"noopener\">Node.js</a> runtime to produce messages to and consume messages from your Kafka instances in OpenShift Streams for Apache Kafka.</p>\n</div>","tasks":["<div class=\"sect1\">\n<h2 id=\"proc-importing-nodejs-sample-code_using-nodejs\">Importing the Node.js sample code</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph _abstract\">\n<p>For this quick start, you&#8217;ll use sample code from the <em>Nodeshift Application Starters</em> <a href=\"https://github.com/nodeshift-starters/reactive-example\" target=\"_blank\" rel=\"noopener\">reactive-example</a> repository in GitHub. After you understand the concepts and tasks in this quick start, you can use your own Node.js applications with OpenShift Streams for Apache Kafka in the same way.</p>\n</div>\n<div class=\"olist\"><div class=\"title\">Procedure</div><div class=\"task-pflist\"><h6 data-ouia-component-type=\"PF4/Title\" data-ouia-safe=\"true\" data-ouia-component-id=\"OUIA-Generated-Title-16\" class=\"pf-c-title pf-m-md task-pflist-title\">Procedure</h6><ol type=\"1\" class=\"pf-c-list task-pflist-list task-pflist-list--proc\"><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>On the command line, clone the Nodeshift Application Starters <a href=\"https://github.com/nodeshift-starters/reactive-example\" target=\"_blank\" rel=\"noopener\">reactive-example</a> repository from GitHub.</p> <div class=\"listingblock\">\n<div class=\"title\">Cloning the reactive-example repository</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code>$ git clone https://github.com/nodeshift-starters/reactive-example.git</code></pre>\n</div>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>In your IDE, open the <code>reactive-example</code> directory of the repository that you cloned.</p> </span></li></ol></div></div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>Is the Node.js example application accessible in your IDE?</p>\n</li>\n</ul>\n</div>\n</div>\n</div>","<div class=\"sect1\">\n<h2 id=\"proc-configuring-nodejs_using-nodejs\">Configuring the Node.js example application to connect to a Kafka instance</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph _abstract\">\n<p>To enable your Node.js application to access a Kafka instance, you must configure a connection by specifying the following details:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>The bootstrap server endpoint for your Kafka instance</p>\n</li>\n<li>\n<p>The generated credentials for your OpenShift Streams for Apache Kafka service account</p>\n</li>\n<li>\n<p>The Simple Authentication and Security Layer (SASL) mechanism that the client will use to authenticate with the Kafka instance</p>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p>In this task, you&#8217;ll create a new configuration file called <code>rhoas.env</code>. In this file, you&#8217;ll set the required bootstrap server and client credentials as environment variables.</p>\n</div>\n<div class=\"olist\"><div class=\"title\">Procedure</div><div class=\"task-pflist\"><h6 data-ouia-component-type=\"PF4/Title\" data-ouia-safe=\"true\" data-ouia-component-id=\"OUIA-Generated-Title-17\" class=\"pf-c-title pf-m-md task-pflist-title\">Procedure</h6><ol type=\"1\" class=\"pf-c-list task-pflist-list task-pflist-list--proc\"><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>In your IDE, create a new file. Save the file with the name <code>rhoas.env</code>, at the root level of the <code>reactive-example</code> directory for the cloned repository.</p> </span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>In the <code>rhoas.env</code> file, add the lines shown in the example. These lines set the bootstrap server and client credentials as environment variables to be used by the Node.js application.</p> <div class=\"listingblock\">\n<div class=\"title\">Setting environment variables in the rhoas.env file</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code>KAFKA_HOST=<em>&lt;bootstrap_server&gt;</em>\nRHOAS_CLIENT_ID=<em>&lt;client_id&gt;</em>\nRHOAS_CLIENT_SECRET=<em>&lt;client_secret&gt;</em>\nKAFKA_SASL_MECHANISM=plain</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>In the preceding example, replace the values in angle brackets (<code>&lt; &gt;</code>) with your own bootstrap server and client credential information.</p>\n</div>\n<div class=\"paragraph\">\n<p>The values are described as follows:</p>\n</div>\n<div class=\"openblock\">\n<div class=\"content\">\n<div class=\"ulist\">\n<ul>\n<li>\n<p><strong>bootstrap_server</strong>: The bootstrap server endpoint for your Kafka instance. To access this information for a Kafka instance in OpenShift Streams for Apache Kafka, select the options menu (three vertical dots). Click <strong>Connection</strong>.</p>\n</li>\n<li>\n<p><strong>client_id</strong>: A client credential generated when you create a service account in OpenShift Streams for Apache Kafka. You&#8217;re prompted to copy and store this credential when you create the service account.</p>\n</li>\n<li>\n<p><strong>client_secret</strong>: A client credential generated when you create a service account in OpenShift Streams for Apache Kafka. You&#8217;re prompted to copy and store this credential when you create the service account.</p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>In this case, observe that the Node.js application uses the SASL/PLAIN authentication method (that is, the value of <code>KAFKA_SASL_MECHANISM</code> is set to <code>plain</code>). This means that the application uses only the client ID and client secret to authenticate with the Kafka instance. The application doesn&#8217;t require an authentication token.</p>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Save the <code>rhoas.env</code> file.</p> </span></li></ol></div></div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>Did you set environment variables for the Kafka instance?</p>\n</li>\n</ul>\n</div>\n</div>\n</div>","<div class=\"sect1\">\n<h2 id=\"proc-creating-countries-topic_using-nodejs\">Creating a Kafka topic in OpenShift Streams for Apache Kafka</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph _abstract\">\n<p>The Node.js application in this quick start uses a Kafka topic called <code>countries</code> to produce and consume messages. In this task, you&#8217;ll create the topic in your Kafka instance.</p>\n</div>\n<div class=\"ulist\"><div class=\"title\">Prerequisites</div><div class=\"task-pflist\"><h6 data-ouia-component-type=\"PF4/Title\" data-ouia-safe=\"true\" data-ouia-component-id=\"OUIA-Generated-Title-18\" class=\"pf-c-title pf-m-md task-pflist-title\">Prerequisites</h6><p class=\"task-pflist-subtitle\">In addtion to the prerequisites for this Quick Start, this step requires:</p><ul class=\"pf-c-list task-pflist-list task-pflist-list--prereq\"><li class=\"task-pflist-list__item--prereq task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>You&#8217;ve created a Kafka instance in OpenShift Streams for Apache Kafka and the instance is in the <strong>Ready</strong> state.</p> </span></li></ul></div></div>\n<div class=\"olist\"><div class=\"title\">Procedure</div><div class=\"task-pflist\"><h6 data-ouia-component-type=\"PF4/Title\" data-ouia-safe=\"true\" data-ouia-component-id=\"OUIA-Generated-Title-19\" class=\"pf-c-title pf-m-md task-pflist-title\">Procedure</h6><ol type=\"1\" class=\"pf-c-list task-pflist-list task-pflist-list--proc\"><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>In the OpenShift Streams for Apache Kafka web console, go to <strong>Streams for Apache Kafka</strong> &gt; <strong>Kafka Instances</strong> and click the name of the Kafka instance that you want to add a topic to.</p> </span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Click <strong>Create topic</strong> and follow the guided steps to define the topic details. Click <strong>Next</strong> to complete each step and click <strong>Finish</strong> to complete the setup.</p> <div class=\"imageblock screencapture\">\n<div class=\"content\">\n<img src=\"./images/sak-create-countries-topic.png\" alt=\"Image of wizard to create a topic\">\n</div>\n<div class=\"title\">Figure 1. Guided steps to define topic details</div>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><strong>Topic name</strong>: Enter <code>countries</code> as the topic name.</p>\n</li>\n<li>\n<p><strong>Partitions</strong>: Set the number of partitions for this topic. This example sets the partition to <code>1</code> for a single partition. Partitions are distinct lists of messages within a topic and enable parts of a topic to be distributed over multiple brokers in the cluster. A topic can contain one or more partitions, enabling producer and consumer loads to be scaled.</p>\n</li>\n<li>\n<p><strong>Message retention</strong>: Set the message retention time and size to the relevant value and increment. This example sets the retention time to <code>7 days</code> and the retention size to <code>Unlimited</code>. Message retention time is the amount of time that messages are retained in a topic before they are deleted or compacted, depending on the cleanup policy. Retention size is the maximum total size of all log segments in a partition before they are deleted or compacted.</p>\n</li>\n<li>\n<p><strong>Replicas</strong>: For this release of OpenShift Streams for Apache Kafka, the replicas are preconfigured. The number of partition replicas for the topic is set to <code>3</code> and the minimum number of follower replicas that must be in sync with a partition leader is set to <code>2</code>. Replicas are copies of partitions in a topic. Partition replicas are distributed over multiple brokers in the cluster to ensure topic availability if a broker fails. When a follower replica is in sync with a partition leader, the follower replica can become the new partition leader if needed.</p>\n<div class=\"paragraph\">\n<p>After you complete the topic setup, the new Kafka topic is listed in the topics table for your Kafka instance. You can now run the Node.js application to start producing and consuming messages.</p>\n</div>\n</li>\n</ul>\n</div></span></li></ol></div></div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>Is the <code>countries</code> topic listed in the topics table?</p>\n</li>\n</ul>\n</div>\n</div>\n</div>","<div class=\"sect1\">\n<h2 id=\"proc-running-nodejs-example-application_using-nodejs\">Running the Node.js example application</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph _abstract\">\n<p>After you configure your Node.js application to connect to a Kafka instance, and you create the required Kafka topic, you&#8217;re ready to run the application.</p>\n</div>\n<div class=\"paragraph\">\n<p>In this task, you&#8217;ll run the following components of the Node.js application:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>A <code>producer-backend</code> component that generates random country names and sends these names to the Kafka topic.</p>\n</li>\n<li>\n<p>A <code>consumer-backend</code> component that consumes the country names from the Kafka topic.</p>\n</li>\n</ul>\n</div>\n<div class=\"ulist\"><div class=\"title\">Prerequisites</div><div class=\"task-pflist\"><h6 data-ouia-component-type=\"PF4/Title\" data-ouia-safe=\"true\" data-ouia-component-id=\"OUIA-Generated-Title-20\" class=\"pf-c-title pf-m-md task-pflist-title\">Prerequisites</h6><p class=\"task-pflist-subtitle\">In addtion to the prerequisites for this Quick Start, this step requires:</p><ul class=\"pf-c-list task-pflist-list task-pflist-list--prereq\"><li class=\"task-pflist-list__item--prereq task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>You&#8217;ve configured the Node.js example application to connect to a Kafka instance.</p> </span></li><li class=\"task-pflist-list__item--prereq task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>You&#8217;ve created the <code>countries</code> Kafka topic.</p> </span></li></ul></div></div>\n<div class=\"olist\"><div class=\"title\">Procedure</div><div class=\"task-pflist\"><h6 data-ouia-component-type=\"PF4/Title\" data-ouia-safe=\"true\" data-ouia-component-id=\"OUIA-Generated-Title-21\" class=\"pf-c-title pf-m-md task-pflist-title\">Procedure</h6><ol type=\"1\" class=\"pf-c-list task-pflist-list task-pflist-list--proc\"><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>On the command line, navigate to the <code>reactive-example</code> directory of the repository that you cloned.</p> <div class=\"listingblock\">\n<div class=\"title\">Navigating to the reactive-example directory</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code>$ cd reactive-example</code></pre>\n</div>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Navigate to the directory for the consumer component. Use Node Package Manager (npm) to install the dependencies for this component.</p> <div class=\"listingblock\">\n<div class=\"title\">Installing dependencies for the consumer component</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code>$ cd consumer-backend\n$ npm install</code></pre>\n</div>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Run the consumer component.</p> <div class=\"listingblock\">\n<div class=\"title\">Running the consumer component</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code>$ node consumer.js</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>You should see the Node.js application run and connect to the Kafka instance. However, because you haven&#8217;t yet run the producer component, the consumer has no country names to display.</p>\n</div>\n<div class=\"paragraph\">\n<p>If the application fails to run, review the error log in the command-line window and address any problems. Also, review the steps in this quick start to ensure that the application and Kafka topic are configured correctly.</p>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Open a second command-line window or tab.</p> </span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>On the second command line, navigate to the <code>reactive-example</code> directory of the repository that you cloned.</p> <div class=\"listingblock\">\n<div class=\"title\">Navigating to the reactive-example directory</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code>$ cd reactive-example</code></pre>\n</div>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Navigate to the directory for the producer component. Use Node Package Manager to install the dependencies for this component.</p> <div class=\"listingblock\">\n<div class=\"title\">Installing dependencies for the producer component</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code>$ cd producer-backend\n$ npm install</code></pre>\n</div>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Run the producer component.</p> <div class=\"listingblock\">\n<div class=\"title\">Running the producer component</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code>$ node producer.js</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>You should see output like that shown in the example.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"title\">Example output from the producer component</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code>$ node producer.js\nGhana\nRéunion\nGuatemala\nLuxembourg\nMayotte\nSyria\nUnited Kingdom\nBolivia\nHaiti</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>As shown in the example, the producer component runs and generates messages that represent country names.</p>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Switch back to the first command-line window.</p> <div class=\"paragraph\">\n<p>You should now see that the consumer component displays the same country names generated by the producer, and in the same order, as shown in the example.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"title\">Example output from the consumer component</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code>$ node consumer.js\nGhana\nRéunion\nGuatemala\nLuxembourg\nMayotte\nSyria\nUnited Kingdom\nBolivia\nHaiti</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The output from both components confirms that they successfully connected to the Kafka instance. The components are using the Kafka topic that you created to produce and consume messages.</p>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>In your IDE, in the <code>producer-backend</code> directory of the repository that you cloned, open the <code>producer.js</code> file.</p> <div class=\"paragraph\">\n<p>Observe that the producer component is configured to process environment variables from the <code>rhoas.env</code> file that you created. The component used the bootstrap server endpoint and client credentials stored in this file to connect to the Kafka instance.</p>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>In the <code>consumer-backend</code> directory, open the <code>consumer.js</code> file.</p> <div class=\"paragraph\">\n<p>Observe that the consumer component is also configured to process environment variables from the <code>rhoas.env</code> file that you created.</p>\n</div></span></li></ol></div></div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>Did the producer component run and start generating random country names?</p>\n</li>\n<li>\n<p>Did the consumer component run and display the same country names generated by the producer, and in the same order?</p>\n</li>\n</ul>\n</div>\n<div id=\"conclusion\" class=\"paragraph\">\n<p>Congratulations! You successfully completed the OpenShift Streams for Apache Kafka Node.js quick start. You&#8217;re now ready to use your own Node.js applications with OpenShift Streams for Apache Kafka.</p>\n</div>\n</div>\n</div>"],"conclusion":"<div id=\"conclusion\" class=\"paragraph\">\n<p>Congratulations! You successfully completed the OpenShift Streams for Apache Kafka Node.js quick start. You&#8217;re now ready to use your own Node.js applications with OpenShift Streams for Apache Kafka.</p>\n</div>","nextQuickStart":["quarkus"]}}