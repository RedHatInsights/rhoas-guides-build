{"apiVersion":"console.openshift.io/v1","kind":"QuickStarts","metadata":{"name":"connectors-getting-started","annotations":{"order":6}},"spec":{"version":0.1,"type":{"text":"Quick Start","color":"green"},"displayName":"Getting started with OpenShift Connectors","durationMinutes":20,"icon":"data:image/svg+xml;base64,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","description":"<div id=\"description\" class=\"paragraph\">\n<p>Learn how to create and set up connectors in OpenShift Connectors.</p>\n</div>","prerequisites":["A Red Hat identity","A running Kafka instance (see the Getting started with Kafka quick start)"],"introduction":"<div id=\"introduction\" class=\"paragraph\">\n<p>Welcome to the quick start for OpenShift Connectors. In this quick start, you&#8217;ll learn how to create a source connector and sink connector and send data to and from OpenShift Streams for Apache Kafka. A source connector allows you to send data from an external system to OpenShift Streams for Apache Kafka. A sink connector allows you to send data from OpenShift Streams for Apache Kafka to an external system.</p>\n</div>","tasks":["<div class=\"sect1\">\n<h2 id=\"proc-configuring-kafka-for-connectors_getting-started-connectors\">Configuring the OpenShift Streams for Apache Kafka instance for use with OpenShift Connectors</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph _abstract\">\n<p>In this step you configure your OpenShift Streams for Apache Kafka for use with OpenShift Connectors. This involves creating topics and setting up access rules for service accounts.</p>\n</div>\n<div class=\"olist\"><div class=\"title\">Procedure</div><div class=\"task-pflist\"><h6 data-ouia-component-type=\"PF4/Title\" data-ouia-safe=\"true\" data-ouia-component-id=\"OUIA-Generated-Title-1\" class=\"pf-c-title pf-m-md task-pflist-title\">Procedure</h6><ol type=\"1\" class=\"pf-c-list task-pflist-list task-pflist-list--proc\"><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>First step</p> </span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Second step</p> </span></li></ol></div></div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>Have you completed these steps?</p>\n</li>\n</ul>\n</div>\n</div>\n</div>","<div class=\"sect1\">\n<h2 id=\"proc-creating-source-connector_getting-started-connectors\">Creating a OpenShift Connectors Source Connector</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph _abstract\">\n<p>In this step you create and configure a source connector. A source connector consumes events from an external system and produces Kafka messages. In this quick start you use the Data Generator Source connector which will produce a Kafka message with a configurable payload at regular intervals to a Kafka topic on your OpenShift Streams for Apache Kafka instance.</p>\n</div>\n<div class=\"olist\"><div class=\"title\">Procedure</div><div class=\"task-pflist\"><h6 data-ouia-component-type=\"PF4/Title\" data-ouia-safe=\"true\" data-ouia-component-id=\"OUIA-Generated-Title-2\" class=\"pf-c-title pf-m-md task-pflist-title\">Procedure</h6><ol type=\"1\" class=\"pf-c-list task-pflist-list task-pflist-list--proc\"><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>In the <a href=\"https://console.redhat.com/application-services/connectors\" class=\"bare\" target=\"_blank\" rel=\"noopener\">https://console.redhat.com/application-services/connectors</a> web console, go to <strong>Connectors</strong> and click <strong>Create connector instance</strong>. Follow the guided steps to define the connector details. Click <strong>Next</strong> to complete each step and click <strong>Finish</strong> to finish the setup.</p> </span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>In the first step you select the connector you want to use. You can browse through the catalog of available connectors. You can also search for a particular connector by name, and filter for sink or source connectors.</p> <div class=\"paragraph\">\n<p>Enter <strong>data</strong> in the search box. You should see only one connector, called <strong>Data Generator Connector</strong>, which is the source connector you use in this quick start. Click the connector box to select the connector, and click <strong>Next</strong> to complete the step.</p>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Select the OpenShift Streams for Apache Kafka instance for the connector to work with. The name of the instance corresponds to the Kafka instance you configured in the previous step. Click on the Kafka instance box to select the instance and click <strong>Next</strong> to complete the step.</p> <div data-reactroot=\"\"><div class=\"pf-c-alert pf-m-inline pf-m-info description-important\" aria-label=\"Info Alert\" data-ouia-component-type=\"PF4/Alert\" data-ouia-safe=\"true\" data-ouia-component-id=\"OUIA-Generated-Alert-info-2\"><div class=\"pf-c-alert__icon\"><svg style=\"vertical-align:-0.125em\" fill=\"currentColor\" height=\"1em\" width=\"1em\" viewBox=\"0 0 512 512\" aria-hidden=\"true\" role=\"img\"><path d=\"M256 8C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm0 110c23.196 0 42 18.804 42 42s-18.804 42-42 42-42-18.804-42-42 18.804-42 42-42zm56 254c0 6.627-5.373 12-12 12h-88c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h12v-64h-12c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h64c6.627 0 12 5.373 12 12v100h12c6.627 0 12 5.373 12 12v24z\"></path></svg></div><h4 class=\"pf-c-alert__title\"><span class=\"pf-u-screen-reader\">Info alert:</span>NOTE</h4><div class=\"pf-c-alert__description\"><span>From this screen you can also create a new Kafka instance by clicking the <strong>Create kafka instance</strong> button.</span></div></div></div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Select the OpenShift Dedicated cluster to host the connector instance. Select the OSD cluster by clicking the box representing the cluster, and click <strong>Next</strong> to complete the step.</p> </span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>In this step you configure the common configuration for your connector. Provide a unique name for the connector and select <strong>Automatically create a service account for this connector</strong>. As an alternative you can also provide the Client ID and Client Secret of an existing service account. If you did set up the OpenShift Streams for Apache Kafka ACL as explained in the previous task of this quick start, the newly created service account has sufficient rights to produce messages to the topic associated with the connector. Click <strong>Next</strong> to complete the step.</p> </span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>In this step you provide the connector specific configuration.</p> <div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Leave the <strong>Data shape Format</strong> to <code>application/octet-stream</code></p>\n</li>\n<li>\n<p><strong>Topic Names</strong>: Enter the name of the topic you created in the previous task of this quick start.</p>\n</li>\n<li>\n<p><strong>Content Type</strong>: Leave to <code>text/plain</code>.</p>\n</li>\n<li>\n<p><strong>Message</strong>: Enter the content of the message that you want to send to the topic, for example <code>Hello World!</code>.</p>\n</li>\n<li>\n<p><strong>Period</strong>: The interval in milliseconds at which events will be sent. Set this to <code>10000</code>, which will produce an event every 10 seconds.</p>\n</li>\n</ol>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Finally configure the error handler for the connector. You can choose between <strong>stop</strong> (the connector shuts down in case of errors), <strong>log</strong> (the error is logged) or <strong>dead letter queue</strong> (the events that cannot be handled by the connector are sent to a dead letter topic of your Kafka instance).\nSelect <code>log</code>.</p> </span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>The next screen shows the configuration properties of your connector. Click <strong>Create connector</strong> to proceed with the deployment of the connector.</p> <div class=\"paragraph\">\n<p>After you complete the connector setup, the new connector is listed in the connectors table. After a couple of seconds, the connector moves to the <strong>Ready</strong> state. At this point the connector starts producing messages to the Kafka topic associated with the connector.</p>\n</div>\n<div class=\"paragraph\">\n<p>From the connectors table, you can stop, start and delete the connector, as well as edit the connector configuration by clicking the options icon (three vertical dots).</p>\n</div></span></li></ol></div></div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>Have you completed these steps?</p>\n</li>\n</ul>\n</div>\n</div>\n</div>","<div class=\"sect1\">\n<h2 id=\"proc-creating-sink-connector_getting-started-connectors\">Creating a OpenShift Connectors Sink Connector</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph _abstract\">\n<p>In this step you create and configure a sink connector. A sink connector consumes events from an Kafka topic and sends them to an external system. In this quickstart you use the HTTP Sink connector which consumes the messages produced by the source connector configured in the previous step and calls a HTTP endpoint with the message payload.</p>\n</div>\n<div class=\"olist\"><div class=\"title\">Procedure</div><div class=\"task-pflist\"><h6 data-ouia-component-type=\"PF4/Title\" data-ouia-safe=\"true\" data-ouia-component-id=\"OUIA-Generated-Title-3\" class=\"pf-c-title pf-m-md task-pflist-title\">Procedure</h6><ol type=\"1\" class=\"pf-c-list task-pflist-list task-pflist-list--proc\"><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Before continuing with the setup of the source connector, you need to setup a HTTP endpoint for the sink connector. One way to do so is to use the free <a href=\"https://webhook.site\" target=\"_blank\" rel=\"noopener\">webhook.site</a> service.\nIn a new browser tab, navigate to the <a href=\"https://webhook.site\" target=\"_blank\" rel=\"noopener\">webhook.site</a>, where you will be given a unique URL that you can leverage as HTTP sink for the connector.</p> </span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>In the <a href=\"https://console.redhat.com/application-services/connectors\" class=\"bare\" target=\"_blank\" rel=\"noopener\">https://console.redhat.com/application-services/connectors</a> web console, go to <strong>Connectors</strong> and click <strong>Create connector instance</strong>. Follow the guided steps to define the connector details. Click <strong>Next</strong> to complete each step and click <strong>Finish</strong> to finish the setup.</p> </span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>In the first step you select the connector you want to use. You can browse through the catalog of available connectors. You can also search for a particular connector by name, and filter for sink or source connectors.</p> <div class=\"paragraph\">\n<p>Enter <strong>http</strong> in the search box. You should see only one connector, called <strong>HTTP Sink</strong>, which is the sink connector you use in this quick start. Click the connector box to select the connector, and click <strong>Next</strong> to complete the step.</p>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Select the OpenShift Streams for Apache Kafka instance for the connector to work with. The name of the instance corresponds to the Kafka instance you configured in the previous step. Click on the Kafka instance box to select the instance and click <strong>Next</strong> to complete the step.</p> </span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Select the OpenShift Dedicated cluster to host the connector instance. Select the OSD cluster by clicking the box representing the cluster, and click <strong>Next</strong> to complete the step.</p> </span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>In this step you configure the common configuration for your connector. Provide a unique name for the connector and select <strong>Automatically create a service account for this connector</strong>. As an alternative you can also provide the Client ID and Client Secret of an existing service account. If you did set up the OpenShift Streams for Apache Kafka ACL as explained in the previous task of this quick start, the newly created service account has sufficient rights to consume messages from the topic associated with the connector. Click <strong>Next</strong> to complete the step.</p> </span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>In this step you provide the connector specific configuration.</p> <div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Leave the <strong>Data shape Format</strong> to <code>application/octet-stream</code></p>\n</li>\n<li>\n<p><strong>Method</strong>: Leave to <code>POST</code>.</p>\n</li>\n<li>\n<p><strong>URL</strong>: Enter your unique URL from <a href=\"https://webhook.site\" target=\"_blank\" rel=\"noopener\">webhook.site</a>.</p>\n</li>\n<li>\n<p><strong>Topic Names</strong>: Enter the name of the topic you created in the first task of this quick start. Use the same topic as for the data sink connector.</p>\n</li>\n</ol>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Finally configure the error handler for the connector. You can choose between <strong>stop</strong> (the connector shuts down in case of errors), <strong>log</strong> (the error is logged) or <strong>dead letter queue</strong> (the events that cannot be handled by the connector are sent to a dead letter topic of your Kafka instance).\nSelect <code>log</code>.</p> </span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>The next screen shows the configuration properties of your connector. Click <strong>Create connector</strong> to proceed with the deployment of the connector.</p> <div class=\"paragraph\">\n<p>After you complete the connector setup, the new connector is listed in the connectors table. After a couple of seconds, the connector moves to the <strong>Ready</strong> state. At this point the connector starts consuming messages from the Kafka topic associated with the connector and sending them to the HTTP sink.</p>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>In the browser tab pointing to <a href=\"https://webhook.site\" target=\"_blank\" rel=\"noopener\">webhook.site</a> you should see the HTTP POST calls from the connector with the message contents as defined in the source connector.</p> </span></li></ol></div></div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>Have you completed these steps?</p>\n</li>\n</ul>\n</div>\n<div id=\"conclusion\" class=\"paragraph\">\n<p>Congratulations! You successfully completed the OpenShift Connectors Getting Started quick start.</p>\n</div>\n</div>\n</div>"],"conclusion":"<div id=\"conclusion\" class=\"paragraph\">\n<p>Congratulations! You successfully completed the OpenShift Connectors Getting Started quick start.</p>\n</div>"}}