{"apiVersion":"console.openshift.io/v1","kind":"QuickStarts","metadata":{"name":"connectors-getting-started","annotations":{"draft":false,"order":6}},"spec":{"version":0.1,"type":{"text":"Quick Start","color":"green"},"displayName":"Getting started with Red Hat OpenShift Connectors","durationMinutes":20,"icon":"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzOCIgaGVpZ2h0PSIzOCIgdmlld0JveD0iMCAwIDM4IDM4Ij48ZGVmcz48c3R5bGU+LmF7ZmlsbDojZmZmO30uYntmaWxsOiNlMDA7fTwvc3R5bGU+PC9kZWZzPjxwYXRoIGQ9Ik0yOCwxSDEwYTksOSwwLDAsMC05LDlWMjhhOSw5LDAsMCwwLDksOUgyOGE5LDksMCwwLDAsOS05VjEwYTksOSwwLDAsMC05LTlaIi8+PHBhdGggY2xhc3M9ImEiIGQ9Ik0yMiwyNS42MjVIMTNhLjYyNS42MjUsMCwwLDEsMC0xLjI1aDlhMi4zNzUsMi4zNzUsMCwwLDAsMC00Ljc1SDE1YTMuNjI1LDMuNjI1LDAsMCwxLDAtNy4yNUgyNWEuNjI1LjYyNSwwLDAsMSwwLDEuMjVIMTVhMi4zNzUsMi4zNzUsMCwwLDAsMCw0Ljc1aDdhMy42MjUsMy42MjUsMCwwLDEsMCw3LjI1WiIvPjxwYXRoIGNsYXNzPSJiIiBkPSJNMjUsMTYuNjI1QTMuNjI1LDMuNjI1LDAsMSwxLDI4LjYyNSwxMywzLjYyODg2LDMuNjI4ODYsMCwwLDEsMjUsMTYuNjI1Wm0wLTZBMi4zNzUsMi4zNzUsMCwxLDAsMjcuMzc1LDEzLDIuMzc3NywyLjM3NzcsMCwwLDAsMjUsMTAuNjI1WiIvPjxwYXRoIGNsYXNzPSJiIiBkPSJNMTMsMjguNjI1QTMuNjI1LDMuNjI1LDAsMSwxLDE2LjYyNSwyNSwzLjYyODg2LDMuNjI4ODYsMCwwLDEsMTMsMjguNjI1Wm0wLTZBMi4zNzUsMi4zNzUsMCwxLDAsMTUuMzc1LDI1LDIuMzc3NywyLjM3NzcsMCwwLDAsMTMsMjIuNjI1WiIvPjwvc3ZnPg==","description":"<div id=\"description\" class=\"exampleblock\">\n<div class=\"content\">\n<div class=\"paragraph\">\n<p>Learn how to configure connections between Red Hat OpenShift Streams for Apache Kafka and third-party systems by using Red Hat OpenShift Connectors.</p>\n</div>\n</div>\n</div>","prerequisites":["Complete the <a href=\"https://console.redhat.com/application-services/learning-resources?quickstart=getting-started\">Getting started with OpenShift Streams for Apache Kafka</a> quick start.","If you plan to use a 60-day OpenShift Dedicated trial cluster to deploy your Connectors instances, a cluster administrator must install the Connectors add-on as described in <a href=\"https://access.redhat.com/documentation/en-us/openshift_connectors/1/guide/15a79de0-8827-4bf1-b445-8e3b3eef7b01\">Adding the Red Hat OpenShift Connectors add-on to your OpenShift Dedicated trial cluster</a>."],"introduction":"<div id=\"introduction\" class=\"exampleblock\">\n<div class=\"content\">\n<div class=\"paragraph\">\n<p>Welcome to the quick start for Red Hat OpenShift Connectors.</p>\n</div>\n<div class=\"paragraph\">\n<p>In this quick start, you learn how to create a source connector and sink connector and send data to and from OpenShift Streams for Apache Kafka.</p>\n</div>\n<div class=\"paragraph\">\n<p>A <strong>source</strong> connector allows you to send data from an external system to OpenShift Streams for Apache Kafka.</p>\n</div>\n<div class=\"paragraph\">\n<p>A <strong>sink</strong> connector allows you to send data from OpenShift Streams for Apache Kafka to an external system.</p>\n</div>\n</div>\n</div>","tasks":["<div class=\"sect1\">\n<h2 id=\"proc-verifying-prerequisites-for-connectors_getting-started-connectors\">Verifying the prerequisites for using Red Hat OpenShift Connectors</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph _abstract\">\n<p>Before you use OpenShift Connectors, you must complete the following prerequisites:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Determine which OpenShift environment to use for deploying your OpenShift Connectors instances.</p>\n</li>\n<li>\n<p>Configure Red Hat OpenShift Streams for Apache Kafka for use with OpenShift Connectors.</p>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p><strong>Determining which OpenShift environment to use for deploying your Connectors instances</strong></p>\n</div>\n<div class=\"paragraph\">\n<p>For Service Preview, you have two choices:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><strong>The hosted evaluation environment</strong></p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>The Connectors instances are hosted on a multitenant OpenShift Dedicated cluster that is owned by Red Hat.</p>\n</li>\n<li>\n<p>You can create four Connectors instances at a time.</p>\n</li>\n<li>\n<p>The evaluation environment applies 48-hour expiration windows, as described in <a href=\"https://access.redhat.com/documentation/en-us/openshift_connectors/1/guide/8190dc9e-249c-4207-bd69-096e5dd5bc64\" target=\"_blank\" rel=\"noopener\">Red Hat OpenShift Connectors Service Preview evaluation guidelines</a>.</p>\n</li>\n</ul>\n</div>\n</li>\n<li>\n<p><strong>Your own trial environment</strong></p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>You have access to your own OpenShift Dedicated trial environment.</p>\n</li>\n<li>\n<p>You can create an unlimited number of Connectors instances.</p>\n</li>\n<li>\n<p>Your OpenShift Dedicated trial cluster expires after 60 days.</p>\n</li>\n<li>\n<p>A cluster administrator must install the OpenShift Connectors add-on as described in <a href=\"https://access.redhat.com/documentation/en-us/openshift_connectors/1/guide/15a79de0-8827-4bf1-b445-8e3b3eef7b01\" target=\"_blank\" rel=\"noopener\">Adding the Red Hat OpenShift Connectors add-on to your OpenShift Dedicated trial cluster</a>.</p>\n</li>\n</ul>\n</div>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p><strong>Configuring Red Hat OpenShift Streams for Apache Kafka for use with OpenShift Connectors</strong></p>\n</div>\n<div class=\"paragraph\">\n<p>Complete the steps in the <a href=\"https://console.redhat.com/application-services/learning-resources?quickstart=getting-started\">Getting started with Red Hat OpenShift Streams for Apache Kafka</a> quick start to set up the following components:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>A <strong>Kafka instance</strong> that you can use for OpenShift Connectors.</p>\n</li>\n<li>\n<p>A <strong>Kafka topic</strong> to store messages sent by data sources and make the messages available to data sinks.</p>\n</li>\n<li>\n<p>A <strong>service account</strong> that allows you to connect and authenticate your Connectors instances with your Kafka instance.</p>\n</li>\n<li>\n<p><strong>Access rules</strong> for the service account that define how your Connectors instances can access and use the topics in your Kafka instance.</p>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Procedure</div>\n<p>Make sure that you have set up the prerequisite components.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>Is the Kafka instance listed in the Kafka instances table and is the Kafka instance in the <strong>Ready</strong> state?</p>\n</li>\n<li>\n<p>Is your service account created in the <strong>Service Accounts</strong> page?</p>\n</li>\n<li>\n<p>Did you save your service account credentials to a secure location?</p>\n</li>\n<li>\n<p>Are the permissions for your service account listed in the <strong>Access</strong> page of the Kafka instance?</p>\n</li>\n<li>\n<p>Is the Kafka topic that you created for Connectors listed in the topics table of the Kafka instance?</p>\n</li>\n<li>\n<p>If you plan to use a 60-day OpenShift Dedicated trial cluster to deploy your OpenShift Connectors instances, has a cluster administrator added the OpenShift Connectors add-on to your trial cluster?</p>\n</li>\n</ul>\n</div>\n</div>\n</div>","<div class=\"sect1\">\n<h2 id=\"proc-creating-source-connector_getting-started-connectors\">Creating a Connectors instance for a data source</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph _abstract\">\n<p>A <strong>source</strong> connector consumes events from an external data source and produces Kafka messages.</p>\n</div>\n<div class=\"paragraph\">\n<p>For this example, you create an instance of the <strong>Data Generator</strong> source connector.</p>\n</div>\n<div class=\"paragraph\">\n<p>You configure your connector to listen for events from the data source and produce a Kafka message for each event.</p>\n</div>\n<div class=\"paragraph\">\n<p>The connector sends the messages at regular intervals to the Kafka topic that you created for your Connectors instances.</p>\n</div>\n<div class=\"olist\"><div class=\"title\">Procedure</div><div class=\"task-pflist\"><h6 data-ouia-component-type=\"PF4/Title\" data-ouia-safe=\"true\" data-ouia-component-id=\"OUIA-Generated-Title-9\" class=\"pf-c-title pf-m-md task-pflist-title\">Procedure</h6><ol type=\"1\" class=\"pf-c-list task-pflist-list task-pflist-list--proc\"><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>In the Red Hat OpenShift Connectors web console, select <strong>Connectors</strong> and then click <strong>Create Connectors instance</strong>.</p> </span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Select the connector that you want to use for connecting to a data source.</p> <div class=\"paragraph\">\n<p>You can browse through the catalog of available connectors. You can also search for a particular connector by name, and filter for sink or source connectors.</p>\n</div>\n<div class=\"paragraph\">\n<p>For example, to find the <strong>Data Generator</strong> source connector, type <strong>data</strong> in the search box. The list filters to show only the <strong>Data Generator Connector</strong> card.</p>\n</div>\n<div class=\"paragraph\">\n<p>Click the card to select the connector, and then click <strong>Next</strong>.</p>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>For <strong>Kafka instance</strong>, click the card for the OpenShift Streams for Apache Kafka instance that you configured for Connectors, and then click <strong>Next</strong>.</p> </span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>On the <strong>Namespace</strong> page, the namespace that you select depends on your OpenShift Dedicated environment. The namespace is the deployment space that hosts your Connectors instances.</p> <div class=\"paragraph\">\n<p>If you&#8217;re using a trial cluster in your own OpenShift Dedicated environment, select the card for the namespace that was created when a system administrator added the Connectors service to your trial cluster, as described in <a href=\"https://access.redhat.com/documentation/en-us/openshift_connectors/1/guide/15a79de0-8827-4bf1-b445-8e3b3eef7b01\" target=\"_blank\" rel=\"noopener\">Adding the Red Hat OpenShift Connectors add-on to your OpenShift Dedicated trial cluster</a>.</p>\n</div>\n<div class=\"paragraph\">\n<p>If you&#8217;re using the evaluation OpenShift Dedicated environment, click <strong>Register eval namespace</strong> to provision a namespace for hosting the Connectors instances that you create.</p>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Click <strong>Next</strong>.</p> </span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Configure the core configuration for your Connectors instance:</p> <div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Type a name for your Connectors instance.</p>\n</li>\n<li>\n<p>Type the <strong>Client ID</strong> and <strong>Client Secret</strong> of the service account that you created for Connectors and then click <strong>Next</strong>.</p>\n</li>\n</ol>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Provide connector-specific configuration. For the <strong>Data Generator</strong>, provide the following information:</p> <div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p><strong>Data shape Format</strong>: Accept the default, <code>application/octet-stream</code>.</p>\n</li>\n<li>\n<p><strong>Topic Names</strong>: Type the name of the topic that you created for Connectors. For example, type <strong>test-topic</strong>.</p>\n</li>\n<li>\n<p><strong>Content Type</strong>: Accept the default, <code>text/plain</code>.</p>\n</li>\n<li>\n<p><strong>Message</strong>: Type the content of the message that you want the Connectors instance to send to the Kafka topic. For example, type <code>Hello World!</code>.</p>\n</li>\n<li>\n<p><strong>Period</strong>: Specify the interval (in milliseconds) at which you want the Connectors instance to send messages to the Kafka topic. For example, specify <code>10000</code>, to send a message every 10 seconds.</p>\n</li>\n</ol>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Optionally, configure the error handling policy for your Connectors instance.</p> <div class=\"paragraph\">\n<p>The options are:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><strong>stop</strong>: (the default) The Connectors instance shuts down when it encounters an error.</p>\n</li>\n<li>\n<p><strong>log</strong>: The Connectors instance sends errors to its log.</p>\n</li>\n<li>\n<p><strong>dead letter queue</strong>: The Connectors instance sends messages that it cannot handle to a dead letter topic that you define for the Connectors Kafka instance.</p>\n<div class=\"paragraph\">\n<p>For example, accept the default <strong>stop</strong> option.</p>\n</div>\n</li>\n</ul>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Click <strong>Next</strong>.</p> </span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Review the summary of the configuration properties and then click <strong>Create Connectors instance</strong>.</p> <div class=\"paragraph\">\n<p>Your Connectors instance is listed in the table of Connectors. After a couple of seconds, the status of your Connectors instance changes to the <strong>Ready</strong> state and it starts producing messages and sending them to its associated Kafka topic.</p>\n</div>\n<div class=\"paragraph\">\n<p>From the Connectors table, you can stop, start, and delete your Connectors instance, as well as edit its configuration, by clicking the options icon (three vertical dots).</p>\n</div></span></li></ol></div></div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>Does your source Connectors instance generate messages?</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the Red Hat OpenShift Application Services web console, select <strong>Streams for Apache Kafka</strong> &gt; <strong>Kafka Instances</strong>.</p>\n</li>\n<li>\n<p>Click the Kafka instance that you created for connectors.</p>\n</li>\n<li>\n<p>Click the <strong>Topics</strong> tab and then click the topic that you specified for your source Connectors instance.</p>\n</li>\n<li>\n<p>Click the <strong>Messages</strong> tab to see a list of <code>Hello World!</code> messages.</p>\n</li>\n</ol>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>","<div class=\"sect1\">\n<h2 id=\"proc-creating-sink-connector_getting-started-connectors\">Creating a Connectors instance for a data sink</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph _abstract\">\n<p>A <strong>sink</strong> connector consumes messages from a Kafka topic and sends them to an external system.</p>\n</div>\n<div class=\"paragraph\">\n<p>For this example, you use the <strong>HTTP Sink</strong> connector which consumes the Kafka messages (produced by the source Connectors instance) and sends the messages to an HTTP endpoint.</p>\n</div>\n<div class=\"olist\"><div class=\"title\">Procedure</div><div class=\"task-pflist\"><h6 data-ouia-component-type=\"PF4/Title\" data-ouia-safe=\"true\" data-ouia-component-id=\"OUIA-Generated-Title-10\" class=\"pf-c-title pf-m-md task-pflist-title\">Procedure</h6><ol type=\"1\" class=\"pf-c-list task-pflist-list task-pflist-list--proc\"><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>In the Red Hat OpenShift Connectors web console, click <strong>Create Connectors instance</strong>.</p> </span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Select the sink connector that you want to use:</p> <div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>For example, type <strong>http</strong> in the search field. The list of Connectors filters to show the <strong>HTTP Sink</strong> connector.</p>\n</li>\n<li>\n<p>Click the <strong>HTTP Sink connector</strong> card and then click <strong>Next</strong>.</p>\n</li>\n</ol>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Select the OpenShift Streams for Apache Kafka instance for the connector to work with.</p> <div class=\"paragraph\">\n<p>For example, select <strong>test</strong> and then click <strong>Next</strong>.</p>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>On the <strong>Namespace</strong> page, the namespace that you select depends on your OpenShift Dedicated environment. The namespace is the deployment space that hosts your Connectors instances.</p> <div class=\"paragraph\">\n<p>If you&#8217;re using a trial cluster on your own OpenShift Dedicated environment, select the card for the namespace that was created when you added the Connectors service to your trial cluster.</p>\n</div>\n<div class=\"paragraph\">\n<p>If you&#8217;re using the evaluation OpenShift Dedicated environment, click the <strong>eval namespace</strong> that you created when you created the source connector.</p>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Click <strong>Next</strong>.</p> </span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Provide the core configuration for your connector:</p> <div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Type a unique name for the connector.</p>\n</li>\n<li>\n<p>Type the <strong>Client ID</strong> and <strong>Client Secret</strong> of the service account that you created for Connectors and then click <strong>Next</strong>.</p>\n</li>\n</ol>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Provide the connector-specific configuration for your Connectors instance. For the <strong>HTTP sink connector</strong>, provide the following information:</p> <div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p><strong>Data shape Format</strong>: Accept the default, <code>application/octet-stream</code>.</p>\n</li>\n<li>\n<p><strong>Method</strong>: Accept the default, <code>POST</code>.</p>\n</li>\n<li>\n<p><strong>URL</strong>: Type your unique URL from the <a href=\"https://webhook.site\" target=\"_blank\" rel=\"noopener\">webhook.site</a>.</p>\n</li>\n<li>\n<p><strong>Topic Names</strong>: Type the name of the topic that you used for the source Connectors instance. For example, type <strong>test-topic</strong>.</p>\n</li>\n</ol>\n</div></span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Optionally, configure the error handling policy for your Connectors instance. For example, select <strong>log</strong> and then click <strong>Next</strong>.</p> </span></li><li class=\"task-pflist-list__item--proc task-pflist-list__item\"><span class=\"task-pflist-list__item__content\"><p>Review the summary of the configuration properties and then click <strong>Create Connectors instance</strong>.</p> <div class=\"paragraph\">\n<p>Your Connectors instance is listed in the table of Connectors.</p>\n</div>\n<div class=\"paragraph\">\n<p>After a couple of seconds, the status of your Connectors instance changes to the <strong>Ready</strong> state. It consumes messages from the associated Kafka topic and sends them to the data sink (for this example, the data sink is the HTTP URL that you provided).</p>\n</div></span></li></ol></div></div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>Open a web browser tab to your custom URL for the <a href=\"https://webhook.site\" target=\"_blank\" rel=\"noopener\">webhook.site</a>. Do you see HTTP POST calls with <code>\"Hello World!!\"</code> messages?</p>\n</li>\n</ul>\n</div>\n<div id=\"conclusion\" class=\"exampleblock\">\n<div class=\"content\">\n<div class=\"paragraph\">\n<p>Congratulations! You successfully completed the Red Hat OpenShift Connectors Getting Started quick start.</p>\n</div>\n</div>\n</div>\n</div>\n</div>"],"conclusion":"<div id=\"conclusion\" class=\"exampleblock\">\n<div class=\"content\">\n<div class=\"paragraph\">\n<p>Congratulations! You successfully completed the Red Hat OpenShift Connectors Getting Started quick start.</p>\n</div>\n</div>\n</div>"}}